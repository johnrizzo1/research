{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSE: Personalized 3D Generative Avatars from A Single Portrait\n",
      "We present PERSE, a method for building an animatable personalized generative\n",
      "avatar from a reference portrait. Our avatar model enables facial attribute\n",
      "editing in a continuous and disentangled latent space to control each facial\n",
      "attribute, while preserving the individual's identity. To achieve this, our\n",
      "method begins by synthesizing large-scale synthetic 2D video datasets, where\n",
      "each video contains consistent changes in the facial expression and viewpoint,\n",
      "combined with a variation in a specific facial attribute from the original\n",
      "input. We propose a novel pipeline to produce high-quality, photorealistic 2D\n",
      "videos with facial attribute editing. Leveraging this synthetic attribute\n",
      "dataset, we present a personalized avatar creation method based on the 3D\n",
      "Gaussian Splatting, learning a continuous and disentangled latent space for\n",
      "intuitive facial attribute manipulation. To enforce smooth transitions in this\n",
      "latent space, we introduce a latent space regularization technique by using\n",
      "interpolated 2D faces as supervision. Compared to previous approaches, we\n",
      "demonstrate that PERSE generates high-quality avatars with interpolated\n",
      "attributes while preserving identity of reference person.\n",
      "2024-12-30 18:59:58+00:00\n",
      "[arxiv.Result.Author('Hyunsoo Cha'), arxiv.Result.Author('Inhee Lee'), arxiv.Result.Author('Hanbyul Joo')]\n",
      "http://arxiv.org/abs/2412.21206v1\n",
      "---\n",
      "Action-Agnostic Point-Level Supervision for Temporal Action Detection\n",
      "We propose action-agnostic point-level (AAPL) supervision for temporal action\n",
      "detection to achieve accurate action instance detection with a lightly\n",
      "annotated dataset. In the proposed scheme, a small portion of video frames is\n",
      "sampled in an unsupervised manner and presented to human annotators, who then\n",
      "label the frames with action categories. Unlike point-level supervision, which\n",
      "requires annotators to search for every action instance in an untrimmed video,\n",
      "frames to annotate are selected without human intervention in AAPL supervision.\n",
      "We also propose a detection model and learning method to effectively utilize\n",
      "the AAPL labels. Extensive experiments on the variety of datasets (THUMOS '14,\n",
      "FineAction, GTEA, BEOID, and ActivityNet 1.3) demonstrate that the proposed\n",
      "approach is competitive with or outperforms prior methods for video-level and\n",
      "point-level supervision in terms of the trade-off between the annotation cost\n",
      "and detection performance.\n",
      "2024-12-30 18:59:55+00:00\n",
      "[arxiv.Result.Author('Shuhei M. Yoshida'), arxiv.Result.Author('Takashi Shibata'), arxiv.Result.Author('Makoto Terao'), arxiv.Result.Author('Takayuki Okatani'), arxiv.Result.Author('Masashi Sugiyama')]\n",
      "http://arxiv.org/abs/2412.21205v1\n",
      "---\n",
      "SoS Certificates for Sparse Singular Values and Their Applications: Robust Statistics, Subspace Distortion, and More\n",
      "We study $\\textit{sparse singular value certificates}$ for random rectangular\n",
      "matrices. If $M$ is an $n \\times d$ matrix with independent Gaussian entries,\n",
      "we give a new family of polynomial-time algorithms which can certify upper\n",
      "bounds on the maximum of $\\|M u\\|$, where $u$ is a unit vector with at most\n",
      "$\\eta n$ nonzero entries for a given $\\eta \\in (0,1)$. This basic algorithmic\n",
      "primitive lies at the heart of a wide range of problems across algorithmic\n",
      "statistics and theoretical computer science.\n",
      "  Our algorithms certify a bound which is asymptotically smaller than the naive\n",
      "one, given by the maximum singular value of $M$, for nearly the widest-possible\n",
      "range of $n,d,$ and $\\eta$. Efficiently certifying such a bound for a range of\n",
      "$n,d$ and $\\eta$ which is larger by any polynomial factor than what is achieved\n",
      "by our algorithm would violate lower bounds in the SQ and low-degree\n",
      "polynomials models. Our certification algorithm makes essential use of the\n",
      "Sum-of-Squares hierarchy. To prove the correctness of our algorithm, we develop\n",
      "a new combinatorial connection between the graph matrix approach to analyze\n",
      "random matrices with dependent entries, and the Efron-Stein decomposition of\n",
      "functions of independent random variables.\n",
      "  As applications of our certification algorithm, we obtain new efficient\n",
      "algorithms for a wide range of well-studied algorithmic tasks. In algorithmic\n",
      "robust statistics, we obtain new algorithms for robust mean and covariance\n",
      "estimation with tradeoffs between breakdown point and sample complexity, which\n",
      "are nearly matched by SQ and low-degree polynomial lower bounds (that we\n",
      "establish). We also obtain new polynomial-time guarantees for certification of\n",
      "$\\ell_1/\\ell_2$ distortion of random subspaces of $\\mathbb{R}^n$ (also with\n",
      "nearly matching lower bounds), sparse principal component analysis, and\n",
      "certification of the $2\\rightarrow p$ norm of a random matrix.\n",
      "2024-12-30 18:59:46+00:00\n",
      "[arxiv.Result.Author('Ilias Diakonikolas'), arxiv.Result.Author('Samuel B. Hopkins'), arxiv.Result.Author('Ankit Pensia'), arxiv.Result.Author('Stefan Tiegel')]\n",
      "http://arxiv.org/abs/2412.21203v1\n",
      "---\n",
      "Distributed Mixture-of-Agents for Edge Inference with Large Language Models\n",
      "Mixture-of-Agents (MoA) has recently been proposed as a method to enhance\n",
      "performance of large language models (LLMs), enabling multiple individual LLMs\n",
      "to work together for collaborative inference. This collaborative approach\n",
      "results in improved responses to user prompts compared to relying on a single\n",
      "LLM. In this paper, we consider such an MoA architecture in a distributed\n",
      "setting, where LLMs operate on individual edge devices, each uniquely\n",
      "associated with a user and equipped with its own distributed computing power.\n",
      "These devices exchange information using decentralized gossip algorithms,\n",
      "allowing different device nodes to talk without the supervision of a\n",
      "centralized server. In the considered setup, different users have their own LLM\n",
      "models to address user prompts. Additionally, the devices gossip either their\n",
      "own user-specific prompts or augmented prompts to generate more refined answers\n",
      "to certain queries. User prompts are temporarily stored in the device queues\n",
      "when their corresponding LLMs are busy. Given the memory limitations of edge\n",
      "devices, it is crucial to ensure that the average queue sizes in the system\n",
      "remain bounded. In this paper, we address this by theoretically calculating the\n",
      "queuing stability conditions for the device queues under reasonable\n",
      "assumptions, which we validate experimentally as well. Further, we demonstrate\n",
      "through experiments, leveraging open-source LLMs for the implementation of\n",
      "distributed MoA, that certain MoA configurations produce higher-quality\n",
      "responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The\n",
      "implementation is available at:\n",
      "https://github.com/purbeshmitra/distributed_moa.\n",
      "2024-12-30 18:59:06+00:00\n",
      "[arxiv.Result.Author('Purbesh Mitra'), arxiv.Result.Author('Priyanka Kaswan'), arxiv.Result.Author('Sennur Ulukus')]\n",
      "http://arxiv.org/abs/2412.21200v1\n",
      "---\n",
      "Sparse chaos in cortical circuits\n",
      "Nerve impulses, the currency of information flow in the brain, are generated\n",
      "by an instability of the neuronal membrane potential dynamics. Neuronal\n",
      "circuits exhibit collective chaos that appears essential for learning, memory,\n",
      "sensory processing, and motor control. However, the factors controlling the\n",
      "nature and intensity of collective chaos in neuronal circuits are not well\n",
      "understood. Here we use computational ergodic theory to demonstrate that basic\n",
      "features of nerve impulse generation profoundly affect collective chaos in\n",
      "neuronal circuits. Numerically exact calculations of Lyapunov spectra,\n",
      "Kolmogorov-Sinai-entropy, and upper and lower bounds on attractor dimension\n",
      "show that changes in nerve impulse generation in individual neurons moderately\n",
      "impact information encoding rates but qualitatively transform phase space\n",
      "structure. Specifically, we find a drastic reduction in the number of unstable\n",
      "manifolds, Kolmogorov-Sinai entropy, and attractor dimension. Beyond a critical\n",
      "point, marked by the simultaneous breakdown of the diffusion approximation, a\n",
      "peak in the largest Lyapunov exponent, and a localization transition of the\n",
      "leading covariant Lyapunov vector, networks exhibit sparse chaos: prolonged\n",
      "periods of near stable dynamics interrupted by short bursts of intense chaos.\n",
      "Analysis of large, more realistically structured networks supports the\n",
      "generality of these findings. In cortical circuits, biophysical properties\n",
      "appear tuned to this regime of sparse chaos. Our results reveal a close link\n",
      "between fundamental aspects of single-neuron biophysics and the collective\n",
      "dynamics of cortical circuits, suggesting that nerve impulse generation\n",
      "mechanisms are adapted to enhance circuit controllability and information flow.\n",
      "2024-12-30 18:55:35+00:00\n",
      "[arxiv.Result.Author('Rainer Engelken'), arxiv.Result.Author('Michael Monteforte'), arxiv.Result.Author('Fred Wolf')]\n",
      "http://arxiv.org/abs/2412.21188v1\n",
      "---\n",
      "Two-component spatiotemporal template for activation-inhibition of speech in ECoG\n",
      "I compute the average trial-by-trial power of band-limited speech activity\n",
      "across epochs of multi-channel high-density electrocorticography (ECoG)\n",
      "recorded from multiple subjects during a consonant-vowel speaking task. I show\n",
      "that previously seen anti-correlations of average beta frequency activity\n",
      "(12-35 Hz) to high-frequency gamma activity (70-140 Hz) during speech movement\n",
      "are observable between individual ECoG channels in the sensorimotor cortex\n",
      "(SMC). With this I fit a variance-based model using principal component\n",
      "analysis to the band-powers of individual channels of session-averaged ECoG\n",
      "data in the SMC and project SMC channels onto their lower-dimensional principal\n",
      "components.\n",
      "  Spatiotemporal relationships between speech-related activity and principal\n",
      "components are identified by correlating the principal components of both\n",
      "frequency bands to individual ECoG channels over time using windowed\n",
      "correlation. Correlations of principal component areas to sensorimotor areas\n",
      "reveal a distinct two-component activation-inhibition-like representation for\n",
      "speech that resembles distinct local sensorimotor areas recently shown to have\n",
      "complex interplay in whole-body motor control, inhibition, and posture. Notably\n",
      "the third principal component shows insignificant correlations across all\n",
      "subjects, suggesting two components of ECoG are sufficient to represent SMC\n",
      "activity during speech movement.\n",
      "2024-12-30 18:50:37+00:00\n",
      "[arxiv.Result.Author('Eric Easthope')]\n",
      "http://arxiv.org/abs/2412.21178v1\n",
      "---\n",
      "Adversarial Attack and Defense for LoRa Device Identification and Authentication via Deep Learning\n",
      "LoRa provides long-range, energy-efficient communications in Internet of\n",
      "Things (IoT) applications that rely on Low-Power Wide-Area Network (LPWAN)\n",
      "capabilities. Despite these merits, concerns persist regarding the security of\n",
      "LoRa networks, especially in situations where device identification and\n",
      "authentication are imperative to secure the reliable access to the LoRa\n",
      "networks. This paper explores a deep learning (DL) approach to tackle these\n",
      "concerns, focusing on two critical tasks, namely (i) identifying LoRa devices\n",
      "and (ii) classifying them to legitimate and rogue devices. Deep neural networks\n",
      "(DNNs), encompassing both convolutional and feedforward neural networks, are\n",
      "trained for these tasks using actual LoRa signal data. In this setting, the\n",
      "adversaries may spoof rogue LoRa signals through the kernel density estimation\n",
      "(KDE) method based on legitimate device signals that are received by the\n",
      "adversaries. Two cases are considered, (i) training two separate classifiers,\n",
      "one for each of the two tasks, and (ii) training a multi-task classifier for\n",
      "both tasks. The vulnerabilities of the resulting DNNs to manipulations in input\n",
      "samples are studied in form of untargeted and targeted adversarial attacks\n",
      "using the Fast Gradient Sign Method (FGSM). Individual and common perturbations\n",
      "are considered against single-task and multi-task classifiers for the LoRa\n",
      "signal analysis. To provide resilience against such attacks, a defense approach\n",
      "is presented by increasing the robustness of classifiers with adversarial\n",
      "training. Results quantify how vulnerable LoRa signal classification tasks are\n",
      "to adversarial attacks and emphasize the need to fortify IoT applications\n",
      "against these subtle yet effective threats.\n",
      "2024-12-30 18:43:21+00:00\n",
      "[arxiv.Result.Author('Yalin E. Sagduyu'), arxiv.Result.Author('Tugba Erpek')]\n",
      "http://arxiv.org/abs/2412.21164v1\n",
      "---\n",
      "Open RAN-Enabled Deep Learning-Assisted Mobility Management for Connected Vehicles\n",
      "Connected Vehicles (CVs) can leverage the unique features of 5G and future\n",
      "6G/NextG networks to enhance Intelligent Transportation System (ITS) services.\n",
      "However, even with advancements in cellular network generations, CV\n",
      "applications may experience communication interruptions in high-mobility\n",
      "scenarios due to frequent changes of serving base station, also known as\n",
      "handovers (HOs). This paper proposes the adoption of Open Radio Access Network\n",
      "(Open RAN/O-RAN) and deep learning models for decision-making to prevent\n",
      "Quality of Service (QoS) degradation due to HOs and to ensure the timely\n",
      "connectivity needed for CV services. The solution utilizes the O-RAN Software\n",
      "Community (OSC), an open-source O-RAN platform developed by the collaboration\n",
      "between the O-RAN Alliance and Linux Foundation, to develop xApps that are\n",
      "executed in the near-Real-Time RIC of OSC. To demonstrate the proposal's\n",
      "effectiveness, an integrated framework combining the OMNeT++ simulator and OSC\n",
      "was created. Evaluations used real-world datasets in urban application\n",
      "scenarios, such as video streaming transmission and over-the-air (OTA) updates.\n",
      "Results indicate that the proposal achieved superior performance and reduced\n",
      "latency compared to the standard 3GPP HO procedure.\n",
      "2024-12-30 18:41:29+00:00\n",
      "[arxiv.Result.Author('Maria Barbosa'), arxiv.Result.Author('Kelvin Dias')]\n",
      "http://arxiv.org/abs/2412.21161v1\n",
      "---\n",
      "Unified dimensionality reduction techniques in chronic liver disease detection\n",
      "Globally, chronic liver disease continues to be a major health concern that\n",
      "requires precise predictive models for prompt detection and treatment. Using\n",
      "the Indian Liver Patient Dataset (ILPD) from the University of California at\n",
      "Irvine's UCI Machine Learning Repository, a number of machine learning\n",
      "algorithms are investigated in this study. The main focus of our research is\n",
      "this dataset, which includes the medical records of 583 patients, 416 of whom\n",
      "have been diagnosed with liver disease and 167 of whom have not. There are\n",
      "several aspects to this work, including feature extraction and dimensionality\n",
      "reduction methods like Linear Discriminant Analysis (LDA), Factor Analysis\n",
      "(FA), t-distributed Stochastic Neighbour Embedding (t-SNE), and Uniform\n",
      "Manifold Approximation and Projection (UMAP). The purpose of the study is to\n",
      "investigate how well these approaches work for converting high-dimensional\n",
      "datasets and improving prediction accuracy. To assess the prediction ability of\n",
      "the improved models, a number of classification methods were used, such as\n",
      "Multi-layer Perceptron, Random Forest, K-nearest neighbours, and Logistic\n",
      "Regression. Remarkably, the improved models performed admirably, with Random\n",
      "Forest having the highest accuracy of 98.31\\% in 10-fold cross-validation and\n",
      "95.79\\% in train-test split evaluation. Findings offer important new\n",
      "perspectives on the choice and use of customized feature extraction and\n",
      "dimensionality reduction methods, which improve predictive models for patients\n",
      "with chronic liver disease.\n",
      "2024-12-30 18:35:02+00:00\n",
      "[arxiv.Result.Author('Anand Karna'), arxiv.Result.Author('Naina Khan'), arxiv.Result.Author('Rahul Rauniyar'), arxiv.Result.Author('Prashant Giridhar Shambharkar')]\n",
      "http://arxiv.org/abs/2412.21156v1\n",
      "---\n",
      "Low coordinate degree algorithms II: Categorical signals and generalized stochastic block models\n",
      "We study when low coordinate degree functions (LCDF) -- linear combinations\n",
      "of functions depending on small subsets of entries of a vector -- can test for\n",
      "the presence of categorical structure, including community structure and\n",
      "generalizations thereof, in high-dimensional data. This complements the first\n",
      "paper of this series, which studied the power of LCDF in testing for continuous\n",
      "structure like real-valued signals perturbed by additive noise. We apply the\n",
      "tools developed there to a general form of stochastic block model (SBM), where\n",
      "a population is assigned random labels and every $p$-tuple of the population\n",
      "generates an observation according to an arbitrary probability measure\n",
      "associated to the $p$ labels of its members. We show that the performance of\n",
      "LCDF admits a unified analysis for this class of models. As applications, we\n",
      "prove tight lower bounds against LCDF (and therefore also against low degree\n",
      "polynomials) for nearly arbitrary graph and regular hypergraph SBMs, always\n",
      "matching suitable generalizations of the Kesten-Stigum threshold. We also prove\n",
      "tight lower bounds for group synchronization and abelian group sumset problems\n",
      "under the \"truth-or-Haar\" noise model, and use our technical results to give an\n",
      "improved analysis of Gaussian multi-frequency group synchronization. In most of\n",
      "these models, for some parameter settings our lower bounds give new evidence\n",
      "for conjectural statistical-to-computational gaps. Finally, interpreting some\n",
      "of our findings, we propose a precise analogy between categorical and\n",
      "continuous signals: a general SBM as above behaves, in terms of the tradeoff\n",
      "between subexponential runtime cost of testing algorithms and the signal\n",
      "strength needed for a testing algorithm to succeed, like a spiked $p_*$-tensor\n",
      "model of a certain order $p_*$ that may be computed from the parameters of the\n",
      "SBM.\n",
      "2024-12-30 18:34:36+00:00\n",
      "[arxiv.Result.Author('Dmitriy Kunisky')]\n",
      "http://arxiv.org/abs/2412.21155v1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "client = arxiv.Client()\n",
    "\n",
    "search = arxiv.Search(\n",
    "  query='machine learning',\n",
    "  max_results=10,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "\n",
    "for r in client.results(search):\n",
    "    print(r.title)\n",
    "    print(r.summary)\n",
    "    print(r.published)\n",
    "    print(r.authors)\n",
    "    print(r.entry_id)\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
